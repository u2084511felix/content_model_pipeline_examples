## Introduction: The Digital Battlefield for Democracy in 2025

In 2025, the contest for the future of liberal democracy is increasingly waged in the digital realm. Artificial intelligence, once heralded as a tool for progress, has become a double-edged sword—empowering both defenders and adversaries of democratic norms. The convergence of AI, social media, and global political interests has created a volatile environment where truth is contested, and the very foundations of democratic discourse are under siege.

This investigative report exposes the actors, technologies, and strategies fueling the erosion of democratic integrity worldwide. Drawing on recent evidence from India, Mexico, and the United States, as well as the global export of digital repression by authoritarian regimes, we reveal how AI-driven disinformation, algorithmic manipulation, and the retreat of tech giants from robust content moderation have left democracies vulnerable to coordinated influence operations. The stakes are clear: without urgent, coordinated action, the digital public square risks becoming a battleground dominated by deception, manipulation, and authoritarian control.

## AI-Driven Disinformation: From Deepfakes to Synthetic Audio

Artificial intelligence has revolutionized the creation and dissemination of disinformation, enabling the production of highly convincing deepfakes, synthetic audio, and fabricated personas at unprecedented scale. In 2025, these technologies have been weaponized to manipulate public opinion, delegitimize political opponents, and erode trust in democratic institutions. The sophistication of AI-generated content—ranging from videos of deceased politicians to voice-cloned robocalls—has made it increasingly difficult for citizens to discern fact from fiction, especially in polarized environments.

Recent elections have seen a surge in the use of AI-driven disinformation. In India, deepfake videos of political figures circulated widely on WhatsApp and Facebook, while in the United States, AI-generated robocalls impersonated candidates to mislead voters in key primaries. Despite the anticipation of a major impact, Meta reported that less than 1% of fact-checked misinformation during the 2024 elections was directly linked to AI. However, the broader effect of algorithmic manipulation and synthetic media continues to undermine public trust, as authoritarian actors like Russia and China leverage these tools to influence democratic processes and destabilize societies.

## Case Studies: India, Mexico, and the United States—Lessons from the 2024 Elections

The 2024 elections in India, Mexico, and the United States provided a critical testing ground for AI-driven disinformation. In India, fabricated videos of deceased politicians and AI-generated audio clips circulated on WhatsApp, fueling rumors and inflaming sectarian tensions. Despite the proliferation of synthetic content, less than 1% of fact-checked misinformation was directly attributed to AI, according to Meta. However, the psychological impact of these campaigns—amplified by algorithmic targeting—contributed to a climate of distrust and confusion among voters.

In Mexico, AI-generated social media personas and fake news websites were deployed to sway public opinion and delegitimize political opponents. The United States saw the use of AI-powered robocalls impersonating candidates, as well as the spread of synthetic audio and video clips designed to mislead voters. While the direct impact of AI-driven disinformation was limited in terms of volume, the persistent use of algorithmic microtargeting and synthetic media eroded public trust in electoral processes. These case studies underscore the need for robust safeguards and real-time fact-checking to protect democratic integrity in the age of AI.

> "While AI-driven deepfakes were widely anticipated as a major threat, their direct impact on the 2024 elections was limited. However, algorithmic manipulation and synthetic media continue to erode public trust."  
> — Meta, November 2025

> "The psychological effect of synthetic content—especially in polarized environments—cannot be underestimated, even if the volume of AI-generated misinformation remains low."  
> — V-Dem Institute, 2025 Report

## Algorithmic Amplification and Microtargeting: The Hidden Threats

Beyond the creation of synthetic content, the real danger lies in how algorithms amplify and microtarget disinformation to vulnerable audiences. Social media platforms use sophisticated AI-driven recommendation systems that prioritize engagement, often at the expense of accuracy or democratic values. This has enabled malicious actors to exploit algorithmic biases, ensuring that divisive or false content reaches those most susceptible to manipulation.

Microtargeting allows for the delivery of tailored disinformation to specific demographic groups, making it harder to detect and counteract. In the 2024 elections, both domestic and foreign actors used data-driven strategies to segment voters and deliver personalized propaganda, deepening polarization and undermining the shared reality necessary for democratic deliberation. The combination of algorithmic amplification and microtargeting represents a profound challenge to electoral integrity and public trust.

## Tech Giants and the Retreat from Content Moderation

Major technology companies, once at the forefront of content moderation, have increasingly shifted responsibility onto users. In 2025, Meta ended its third-party fact-checking program in the United States, replacing it with a community-driven model similar to X (formerly Twitter). This move, coupled with the loosening of moderation policies on political and social issues, has left platforms more vulnerable to coordinated disinformation campaigns and viral falsehoods.

Other platforms, such as TikTok and YouTube, have also leaned on user-driven moderation and AI tools to combat synthetic content and deepfakes. While regulatory frameworks like the EU’s Digital Services Act and the UK’s focus on AI labeling have emerged, enforcement remains inconsistent, and detection often lags behind evolving threats. The retreat of tech giants from proactive moderation has created an environment where falsehoods can proliferate, outpacing current detection and mitigation efforts.

> "The retreat of major technology companies from proactive content moderation has created an environment where falsehoods and influence operations can proliferate, outpacing current detection and mitigation efforts."  
> — United Nations, July 2025

> "Meta’s shift to user-driven models has left platforms more vulnerable to coordinated disinformation campaigns and viral falsehoods."  
> — Digital Regulators Forum, November 2025

## Authoritarian Exports: China, Russia, and the Global Spread of Digital Repression

Authoritarian regimes, particularly China and Russia, have become global exporters of AI-powered surveillance and disinformation tools. These technologies are not only used for domestic control but are actively deployed abroad to manipulate public opinion, destabilize democracies, and reinforce authoritarian influence. China’s Digital Silk Road initiative has facilitated the spread of digital authoritarianism across Asia, Africa, and Eastern Europe, providing governments with the means to monitor, intimidate, and silence dissent.

In 2025, China intensified AI-driven influence operations targeting Taiwan, Hong Kong, and U.S. lawmakers, while Russia expanded its use of deepfake campaigns against political leaders in Europe and beyond. These efforts include voice cloning, fake news websites, and AI-generated social media personas, often operating at a scale and sophistication that outpaces detection. The global export of digital repression underscores the urgent need for coordinated international responses to defend democratic institutions and civil liberties.

> "Authoritarian regimes, particularly China and Russia, are not only using AI technologies for domestic control but are actively exporting digital repression and disinformation tactics abroad."  
> — European Commission, 2025

> "The global export of digital repression underscores the urgent need for coordinated international responses to defend democratic institutions and civil liberties."  
> — V-Dem Institute, 2025

## Private AI Firms and the Weaponization of Data

The rise of private AI firms has added a new dimension to the weaponization of data in the digital battlefield. These companies, often operating with limited oversight, build detailed data profiles on lawmakers, activists, and ordinary citizens, enabling targeted influence operations and surveillance. In 2025, reports surfaced of private firms selling AI-powered tools to both state and non-state actors, facilitating the creation of synthetic personas and the microtargeting of disinformation campaigns.

The lack of transparency and accountability in the private AI sector has made it difficult to trace the origins and impact of these operations. While some platforms have disrupted coordinated inauthentic behavior, the rapid evolution and scalability of AI-driven disinformation continue to outpace detection and mitigation efforts. The involvement of private actors in the digital battlefield highlights the need for stronger regulatory frameworks and international cooperation to safeguard democratic processes.

## Democratic Safeguards: The FIMI Framework, Digital Services Act, and Beyond

In response to the escalating threat of AI-driven disinformation, democratic governments and international organizations have advanced new regulatory frameworks. The European Union’s FIMI (Foreign Information Manipulation and Interference) framework and the Digital Services Act (DSA) represent significant steps toward enforcing transparency, accountability, and platform responsibility. Regulation 2024/900 on political ad transparency, set to apply from October 2025, aims to curb the influence of opaque and manipulative political advertising.

Despite these efforts, enforcement remains fragmented and insufficient to counter the scale, speed, and complexity of technologically enabled subversion. The V-Dem Institute’s 2025 report highlights ongoing global autocratization and the limitations of current safeguards. Initiatives like India’s misinformation tipline and Taiwan’s real-time fact-checking offer promising models, but the rapid evolution of AI-driven threats demands urgent, coordinated, and multi-stakeholder action to defend the digital public square.

> "Current democratic safeguards and regulatory efforts, such as the EU’s FIMI framework and Digital Services Act, remain fragmented and insufficient to counter the scale, speed, and complexity of technologically enabled subversion."  
> — Digital Regulators Forum, November 2025

## Obstacles to Reform: Political and Financial Resistance

Efforts to regulate and safeguard democratic discourse face significant resistance from powerful political and financial interests. In 2025, the EU advanced its FIMI framework and imposed sanctions on malicious actors, but enforcement has been hampered by lobbying from tech giants and concerns over free expression. Meta, for example, faced a $290 million fine in Nigeria and criticism for failing to curb inauthentic behavior linked to pro-Kremlin campaigns, yet continues to resist more stringent oversight.

Authoritarian regimes have intensified their use of AI-driven disinformation, exploiting regulatory gaps and platform vulnerabilities. The EU’s Code of Practice on Disinformation has pushed platforms to demonetize harmful content, but concerns persist over enforcement gaps and the ability of AI-generated content to bypass safeguards during critical electoral periods. The ongoing tension between platform accountability, political interests, and the protection of civil liberties remains a major obstacle to meaningful reform.

> "Efforts to regulate and safeguard democratic discourse face significant resistance from powerful political and financial interests."  
> — European Commission, 2025

> "The ongoing tension between platform accountability, political interests, and the protection of civil liberties remains a major obstacle to meaningful reform."  
> — V-Dem Institute, 2025

## Conclusion: Defending the Digital Public Square

AI-driven disinformation campaigns represent an escalating and sophisticated threat to democratic discourse and electoral integrity. Authoritarian regimes and private actors are leveraging advanced technologies to manipulate public opinion, destabilize democracies, and erode public trust in information. The proliferation of AI-generated synthetic content, including deepfakes and synthetic audio, has made it increasingly difficult for citizens to discern truth from manipulation, especially in polarized environments.

Current democratic safeguards and regulatory efforts, such as the EU’s FIMI framework and Digital Services Act, remain fragmented and insufficient to counter the scale, speed, and complexity of technologically enabled subversion. The urgent need for coordinated, multi-stakeholder action is clear. Defending the digital public square requires robust digital verification standards, transparent platform policies, and international cooperation to protect the foundations of liberal democracy from technologically enabled subversion.

> "Defending the digital public square requires robust digital verification standards, transparent platform policies, and international cooperation to protect the foundations of liberal democracy from technologically enabled subversion."  
> — United Nations, July 2025
